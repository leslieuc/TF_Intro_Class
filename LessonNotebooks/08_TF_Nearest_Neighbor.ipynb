{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbor Methods\n",
    "\n",
    "<img src='../pics/kNN-1.png' width=300px/>\n",
    "\n",
    "* Nearest neighbor methods typically use the training set as the model and make predictions on new points based on how close they are to points in the training set. \n",
    "* In its simplest form, you could simply set your prediction to be the class of the closest training data point.\n",
    "* But, since most datasets are noisy, the most common method nearest neighbor method is to take a weighted average of a set of k nearest neighbors (KNN).\n",
    "* Given a training dataset (x1, x2, ..., xn),  with corresponding targets (y1, y2, ..., yn), we can make a prediction on a point, z, by looking at a set of nearest neighbors. The actual method of prediction depends on whether or not we are doing regression (continuous y) or classification (discrete y).\n",
    "* For discrete classification targets, the prediction may be given by a maximum voting scheme weighted by the distance to the prediction point:\n",
    "\n",
    "**_prediction(z) = max ( weighted sum of distances of points in each class )_**\n",
    "\n",
    "* Here, our prediction is the maximum weighted value over all classes $\\mathrm{(j)}$, where the weighted distance from the prediction point is usually given by the L1 or L2 distance functions.\n",
    "* Continuous targets are very similar, but we usually just compute a weighted average of the target variable $\\mathrm{(y)}$ by distance.\n",
    "* There are many different specifications of distance metrics that we can choose, with the L1 and L2 metrics some of the most common.\n",
    "* We also have to choose how to weight the distances. A straightforward way to weight the distances is by the distance itself. Points that are further away from our prediction should have less impact than nearer points. The most common way to weight is by the normalized inverse of the distance. \n",
    "* Note that k-NN is an aggregating method. For regression, we are performing a weighted average of neighbors. Because of this, predictions will be less extreme and less varied than the actual targets. The magnitude of this effect will be determined by k, the number of neighbors in the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data:\n",
    "We will use the 1970s Boston housing dataset which is available through the UCI ML data repository. \n",
    "\n",
    "----------x-values-----------\n",
    "* CRIM   : per capita crime rate by town\n",
    "* ZN     : prop. of res. land zones\n",
    "* INDUS  : prop. of non-retail business acres\n",
    "* CHAS   : Charles river dummy variable\n",
    "* NOX    : nitrix oxides concentration / 10 M\n",
    "* RM     : Avg. # of rooms per building\n",
    "* AGE    : prop. of buildings built prior to 1940\n",
    "* DIS    : Weighted distances to employment centers\n",
    "* RAD    : Index of radian highway access\n",
    "* TAX    : Full tax rate value per $10k\n",
    "* PTRATIO: Pupil/Teacher ratio by town\n",
    "* B      : 1000*(Bk-0.63)^2, Bk=prop. of blacks\n",
    "* LSTAT  : % lower status of pop\n",
    "\n",
    "------------y-value-----------\n",
    "* MEDV   : Median Value of homes in $1,000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "* Note that we're only using certain columns for prediction - e.g. we're not using id variables or variables with very low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "housing_header = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "cols_used = ['CRIM', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "num_features = len(cols_used)\n",
    "housing_file = requests.get(housing_url)\n",
    "housing_data = [[float(x) for x in y.split(' ') if len(x)>=1] for y in housing_file.text.split('\\n') if len(y)>=1]\n",
    "\n",
    "y_vals = np.transpose([np.array([y[13] for y in housing_data])])\n",
    "x_vals = np.array([[x for i,x in enumerate(y) if housing_header[i] in cols_used] for y in housing_data])\n",
    "\n",
    "## Min-Max Scaling - scaling between 0 and 1\n",
    "x_vals = (x_vals - x_vals.min(0)) / x_vals.ptp(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)  #make results reproducible\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.831), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 10) (86, 10) (420, 1) (86, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_vals_train.shape, x_vals_test.shape,y_vals_train.shape,y_vals_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare k-value and batch size\n",
    "k = 4\n",
    "# batch size must divide evenly into the length of the test set\n",
    "batch_size= 2 #len(x_vals_test)\n",
    "\n",
    "# Create graph\n",
    "sess = tf.Session()\n",
    "\n",
    "# Placeholders\n",
    "x_data_train = tf.placeholder(shape=[None, num_features], dtype=tf.float32)\n",
    "x_data_test = tf.placeholder(shape=[None, num_features], dtype=tf.float32)\n",
    "y_target_train = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "y_target_test = tf.placeholder(shape=[None, 1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Simple Distance Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1\n",
    "distance = tf.reduce_sum(tf.abs(tf.subtract(x_data_train, tf.expand_dims(x_data_test,1))), axis=2)\n",
    "\n",
    "# L2\n",
    "#distance = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(x_data_train, tf.expand_dims(x_data_test,1))), reduction_indices=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Weighted Distance Metric\n",
    "* Here we scale the distance functions for each feature by a factor of its standard deviation, which gives a more accurate view of which points are the \"closest\" neighbors or not.\n",
    "* This scaling factor can also be used to down-weight or up-weight features in the nearest neighbor distance calculation, which can be useful in situations where we trust some features more or less than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create distance metric weight matrix weighted by standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_diagonal = x_vals.std(0)\n",
    "weight_matrix = tf.cast(tf.diag(weight_diagonal), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare weighted distance metric\n",
    "$$L2 = \\sqrt{(x-y)^T * A * (x-y)}$$\n",
    "* Break the distance function into components for readability.\n",
    "* We need to tile the weight matrix by the batch size so we use the `batch_matmul()` function to perform batch matrix multiplication across the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtraction_term =  tf.subtract(x_data_train, tf.expand_dims(x_data_test,1))\n",
    "first_product = tf.matmul(subtraction_term, tf.tile(tf.expand_dims(weight_matrix,0), [batch_size,1,1]))\n",
    "second_product = tf.matmul(first_product, tf.transpose(subtraction_term, perm=[0,2,1]))\n",
    "distance = tf.sqrt(tf.matrix_diag_part(second_product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find minimum distance for prediction\n",
    "* After calculating all the training distances for each test point, we need to return the top k nearest neighbors, which we do with the `top_k()` function.\n",
    "* Since the `top_k` function returns the largest values, and we want the smallest distances, we return the largest of the negative distance values.\n",
    "* We then want make predictions as the weighted average of the distances of the top k neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #1 MSE: 5.732\n",
      "Batch #2 MSE: 1.187\n",
      "Batch #3 MSE: 0.742\n",
      "Batch #4 MSE: 1.135\n",
      "Batch #5 MSE: 1.23\n",
      "Batch #6 MSE: 6.432\n",
      "Batch #7 MSE: 10.732\n",
      "Batch #8 MSE: 3.762\n",
      "Batch #9 MSE: 1.553\n",
      "Batch #10 MSE: 0.356\n",
      "Batch #11 MSE: 8.375\n",
      "Batch #12 MSE: 5.004\n",
      "Batch #13 MSE: 9.412\n",
      "Batch #14 MSE: 51.453\n",
      "Batch #15 MSE: 8.653\n",
      "Batch #16 MSE: 29.837\n",
      "Batch #17 MSE: 5.902\n",
      "Batch #18 MSE: 18.097\n",
      "Batch #19 MSE: 4.053\n",
      "Batch #20 MSE: 11.295\n",
      "Batch #21 MSE: 147.843\n",
      "Batch #22 MSE: 76.543\n",
      "Batch #23 MSE: 7.055\n",
      "Batch #24 MSE: 1.963\n",
      "Batch #25 MSE: 9.016\n",
      "Batch #26 MSE: 13.173\n",
      "Batch #27 MSE: 20.936\n",
      "Batch #28 MSE: 32.896\n",
      "Batch #29 MSE: 9.488\n",
      "Batch #30 MSE: 97.767\n",
      "Batch #31 MSE: 22.78\n",
      "Batch #32 MSE: 23.397\n",
      "Batch #33 MSE: 13.469\n",
      "Batch #34 MSE: 18.261\n",
      "Batch #35 MSE: 6.264\n",
      "Batch #36 MSE: 48.655\n",
      "Batch #37 MSE: 3.42\n",
      "Batch #38 MSE: 5.615\n",
      "Batch #39 MSE: 3.842\n",
      "Batch #40 MSE: 0.508\n",
      "Batch #41 MSE: 1.619\n",
      "Batch #42 MSE: 1.731\n",
      "Batch #43 MSE: 13.07\n"
     ]
    }
   ],
   "source": [
    "#prediction = tf.arg_min(distance, 0)\n",
    "top_k_xvals, top_k_indices = tf.nn.top_k(tf.negative(distance), k=k)\n",
    "x_sums = tf.expand_dims(tf.reduce_sum(top_k_xvals, 1),1)\n",
    "x_sums_repeated = tf.matmul(x_sums,tf.ones([1, k], tf.float32))\n",
    "x_val_weights = tf.expand_dims(tf.div(top_k_xvals,x_sums_repeated), 1)\n",
    "\n",
    "# tf.gather is just an array-lookup function\n",
    "top_k_yvals = tf.gather(y_target_train, top_k_indices)\n",
    "prediction = tf.squeeze(tf.matmul(x_val_weights,top_k_yvals), axis=[1])\n",
    "#prediction = tf.reduce_mean(top_k_yvals, 1)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = tf.div(tf.reduce_sum(tf.square(tf.subtract(prediction, y_target_test))), batch_size)\n",
    "\n",
    "# Calculate how many loops over training data\n",
    "num_loops = int(np.ceil(len(x_vals_test)/batch_size))\n",
    "\n",
    "predictions = []\n",
    "y_batches = []\n",
    "for i in range(num_loops):\n",
    "    min_index = i*batch_size\n",
    "    max_index = min((i+1)*batch_size,len(x_vals_train))\n",
    "    x_batch = x_vals_test[min_index:max_index]\n",
    "    y_batch = y_vals_test[min_index:max_index]\n",
    "    temp_predictions = sess.run(prediction, feed_dict={x_data_train: x_vals_train, x_data_test: x_batch,\n",
    "                                         y_target_train: y_vals_train, y_target_test: y_batch})\n",
    "    batch_mse = sess.run(mse, feed_dict={x_data_train: x_vals_train, x_data_test: x_batch,\n",
    "                                         y_target_train: y_vals_train, y_target_test: y_batch})\n",
    "    predictions.append(temp_predictions)\n",
    "    y_batches.append(y_batch)\n",
    "    print('Batch #' + str(i+1) + ' MSE: ' + str(np.round(batch_mse,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWUE44ZuZFYQTvplZQfwffC2RKv6JzR4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7698b5fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "predictions = np.array(predictions).reshape(-1,1)\n",
    "y_batches = np.array(y_batches).reshape(-1,1)\n",
    "# Plot prediction and actual distribution\n",
    "bins = np.linspace(5, 50, 45)\n",
    "\n",
    "plt.hist(predictions, bins, alpha=0.6, label='Prediction')\n",
    "plt.hist(y_batches, bins, alpha=0.4, label='Actual')\n",
    "plt.title('Histogram of Predicted and Actual Values')\n",
    "plt.xlabel('Med Home Value in $1,000s')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
